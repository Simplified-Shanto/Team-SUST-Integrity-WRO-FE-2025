#-----Full forms------------------
#LLMC - Low level microcontroller
#SBC - Single Board Computer

#!/usr/bin/env python3

# --- Configuration ---
DEVELOPING   = 0 # The code is in development mode, and we'll show processed images at different stages, 
                 # otherwise, there'll be no ui output of the code thus we can run it headless on startup i
                 # in raspberry pie. 

CAM_TYPE = 0 # 0  = Raspicamera, 1  = webcam. 
FOCAL_LENGTH_PX = 535 #Focal length in pixels - 530 for micropack webcam
SERIAL_READY = 1 #Whether a serial device is connected or not
CAMERA_INDEX = 0    # Select which cam will be used  #1 - laptop's camera #0 - micropack webcam
MACHINE = 1  # 0 = WINDOWS, 1 = LINUX OS, (Raspberry pie)
COM_PORT = 4
TUNE_HSV = 1 # whether we want to tune the hsv color values for different image elements. 

FRAME_WIDTH = 640
FRAME_HEIGHT = 480
MIN_OBJECT_AREA = 1500  # Minimum contour area to consider an object (adjust as needed)
MIN_LINE_AREA = 500

if MACHINE == 1 and CAM_TYPE==0: 
    from picamera2 import Picamera2
import numpy as np
import cv2
import serial
import time
import math
import os

KNOWN_WIDTH_CM = 5.0  ## Here we are using teh WRO future engineers game obstacle as sample object Object's physical width # KNOWN_WIDTH_CM should correspond to the 'w' (width)  of the object
KNOWN_DISTANCE_CM = 30

if SERIAL_READY==1 and MACHINE == 1:
    ser = serial.Serial("/dev/esp32_serial", 115200, timeout = 1)
    time.sleep(2)
    # At startup we have a fresh buffer with nothing in it. 
    ser.reset_input_buffer()
elif SERIAL_READY==1 and MACHINE ==0: 
    ser = serial.Serial(f'COM{COM_PORT}', 115200, timeout = 1.0)
    time.sleep(2)
    ser.reset_input_buffer()


def stackImages(scale,imgArray):
    rows = len(imgArray)
    cols = len(imgArray[0])
    rowsAvailable = isinstance(imgArray[0], list)
    width = imgArray[0][0].shape[1]
    height = imgArray[0][0].shape[0]
    if rowsAvailable:
        for x in range ( 0, rows):
            for y in range(0, cols):
                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:
                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)
                else:
                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)
                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)
        imageBlank = np.zeros((height, width, 3), np.uint8)
        hor = [imageBlank]*rows
        hor_con = [imageBlank]*rows
        for x in range(0, rows):
            hor[x] = np.hstack(imgArray[x])
        ver = np.vstack(hor)
    else:
        for x in range(0, rows):
            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:
                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)
            else:
                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)
            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)
        hor= np.hstack(imgArray)
        ver = hor
    return ver
def estimate_distance(perceived_dimension_px):
    """Estimates distance to an object given its perceived dimension in pixels.
    Uses KNOWN_WIDTH_CM and FOCAL_LENGTH_PX from global config."""
    if perceived_dimension_px == 0:
        return 0.0
    return round((KNOWN_WIDTH_CM * FOCAL_LENGTH_PX) / perceived_dimension_px, 2)

    # Define bounds for the general trackbar mask (works fine in bright light condition ) 
# lower_bound_green = np.array([15, 10, 0])
# upper_bound_green = np.array([46, 255, 255])

# lower_bound1_red = np.array([0, 181, 70])
# upper_bound1_red = np.array([5, 255, 255])

# lower_bound2_red = np.array([165, 97, 00])
# upper_bound2_red = np.array([179, 255, 255])

# blue_line_lower_bound = np.array([111, 93 , 00 ])
# blue_line_upper_bound = np.array([150, 255, 255 ])

# orange_line_lower_bound = np.array([174, 102, 14 ])
# orange_line_upper_bound = np.array([179, 170, 255 ])



    # # Define bounds for the general trackbar mask (works fine in low light condition) 
lower_bound_green = np.array([25, 135, 50])
upper_bound_green = np.array([55, 255, 255])

lower_bound1_red = np.array([0, 181, 70])
upper_bound1_red = np.array([5, 255, 255])

lower_bound2_red = np.array([175, 181, 70])
upper_bound2_red = np.array([179, 255, 255])

blue_line_lower_bound = np.array([99, 40 , 90 ])
blue_line_upper_bound = np.array([135, 255, 255 ])

orange_line_lower_bound = np.array([2, 67, 59])
orange_line_upper_bound = np.array([15, 233, 255 ])



if TUNE_HSV==1 and DEVELOPING==1: 
    cv2.namedWindow("Vehicle Parameters", cv2.WINDOW_NORMAL)  # This window will be used to tune different parameters of the vehicle, like speed, pid values etc via serial commands
    cv2.resizeWindow("Vehicle Parameters", 600, 400)
    cv2.waitKey(100)

    def changeVehicleSpeed(speed):
        if SERIAL_READY: 
            ser.write(f"s:{speed};".encode("utf-8"))
        if DEVELOPING==1: 
            print(f"Serial: s:{speed};")
     
    cv2.createTrackbar("Speed", "Vehicle Parameters", 100, 255, changeVehicleSpeed)
    def nothing(x):
        pass
     # --- Create General Trackbar Window
    cv2.namedWindow("HSV Trackbars", cv2.WINDOW_NORMAL) #WINDOW_NORMAL is a flag that let's user resize the window, by default its, cv2.AUTOSIZE, which makes the window fit to the size of the content and it is unresizable. 
    cv2.resizeWindow("HSV Trackbars", 600, 600)
    cv2.waitKey(100)  # Wait 100ms for the window to draw
    # Create trackbars for general HSV lower and upper bounds
    #                                          I            ntial value of trackbar    Highest value of the trackbar
    cv2.createTrackbar("Green L - H", "HSV Trackbars", lower_bound_green[0],                    179,             nothing)
    cv2.createTrackbar("Green L - S", "HSV Trackbars", lower_bound_green[1], 255, nothing)
    cv2.createTrackbar("Green L - V", "HSV Trackbars", lower_bound_green[2], 255, nothing)
    cv2.createTrackbar("Green U - H", "HSV Trackbars", upper_bound_green[0], 179, nothing)
    cv2.createTrackbar("Green U - S", "HSV Trackbars", upper_bound_green[1], 255, nothing)
    cv2.createTrackbar("Green U - V", "HSV Trackbars", upper_bound_green[2], 255, nothing)
    # HSV tuning trackbars for red objects
    cv2.createTrackbar("Red L - H1", "HSV Trackbars", lower_bound1_red[0], 179, nothing)
    cv2.createTrackbar("Red L - H2", "HSV Trackbars", lower_bound2_red[0], 179, nothing)
    cv2.createTrackbar("Red L - S", "HSV Trackbars", lower_bound1_red[1], 255, nothing)
    cv2.createTrackbar("Red L - V", "HSV Trackbars", lower_bound1_red[2], 255, nothing)
    cv2.createTrackbar("Red U - H1", "HSV Trackbars", upper_bound1_red[0], 179, nothing)
    cv2.createTrackbar("Red U - H2", "HSV Trackbars", upper_bound2_red[0], 179, nothing)
    cv2.createTrackbar("Red U - S", "HSV Trackbars", upper_bound2_red[1], 255, nothing)
    cv2.createTrackbar("Red U - V", "HSV Trackbars", upper_bound2_red[2], 255, nothing)

    cv2.namedWindow("Line HSV trackbars", cv2.WINDOW_NORMAL)
    cv2.resizeWindow("Line HSV trackbars", 600, 600)
    cv2.waitKey(100) 
    cv2.createTrackbar("Blue Line L_H", "Line HSV trackbars",blue_line_lower_bound[0], 179, nothing )
    cv2.createTrackbar("Blue Line L_S", "Line HSV trackbars",blue_line_lower_bound[1], 255, nothing )
    cv2.createTrackbar("Blue Line L_V", "Line HSV trackbars",blue_line_lower_bound[2], 255, nothing )
    cv2.createTrackbar("Blue Line U_H", "Line HSV trackbars",blue_line_upper_bound[0], 179, nothing )
    cv2.createTrackbar("Blue Line U_S", "Line HSV trackbars",blue_line_upper_bound[1], 255, nothing )
    cv2.createTrackbar("Blue Line U_V", "Line HSV trackbars",blue_line_upper_bound[2], 255, nothing )

    cv2.createTrackbar("Orange Line L_H", "Line HSV trackbars", orange_line_lower_bound[0], 179, nothing)
    cv2.createTrackbar("Orange Line L_S", "Line HSV trackbars", orange_line_lower_bound[1], 179, nothing)
    cv2.createTrackbar("Orange Line L_V", "Line HSV trackbars", orange_line_lower_bound[2], 179, nothing)
    cv2.createTrackbar("Orange Line U_H", "Line HSV trackbars", orange_line_upper_bound[0], 179, nothing)
    cv2.createTrackbar("Orange Line U_S", "Line HSV trackbars", orange_line_upper_bound[1], 179, nothing)
    cv2.createTrackbar("Orange Line U_V", "Line HSV trackbars", orange_line_upper_bound[2], 179, nothing)

# # --- Initialize camera ---
if MACHINE == 0:  # Windows
        cap = cv2.VideoCapture(CAMERA_INDEX, cv2.CAP_DSHOW)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)

elif MACHINE==1:             # Linux / Raspberry Pi
    if CAM_TYPE==0: # Pi camera 
        picam2 = Picamera2()
        config = picam2.create_preview_configuration(main={"size": (640, 480)})
        picam2.configure(config)
        picam2.start()
    elif CAM_TYPE==1:  # USB webcam. 
        cap = cv2.VideoCapture(CAMERA_INDEX)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)

if SERIAL_READY: 
    ser.reset_input_buffer()
    time.sleep(1)
    ser.write('r'.encode('utf-8')) # indicates that the SBC is ready for image processing
    if DEVELOPING:
        print("Serial: r")

#-------Flags------------------
serialFlag = 0      # Whether we've sent the distance of the red obstacle to the LLM 
serialFlag2 = 0     # Whether we've sent the distance of the green obstacle to the LLM
directionSentFlag = 0 # Whether we've reported the direction of the round to the LLM

lineInterval = 0
stopDelay = 0
line_count = -1

# --- Video Processing Loop ---
while True:
    if ser.in_waiting > 0:  # If there's some message from Arduino
        command = ser.readline().decode('utf-8').strip()  # Read line & strip newline/spaces
        if DEVELOPING == 1:
            print("Raw command = ", command)
        # Case 1: simple one-letter command like 'r' or 'd'
        if command == "r":   # The lap is starting via button press, so start counting lines
            line_count = 0
            if DEVELOPING: print("Lap started (reset line count).")

        elif command == "d" : 
            if MACHINE==1: #Linux 
                os.system("sudo shutdown now") # Shutdown immediately
            elif MACHINE==0: # Windows
                if SERIAL_READY:
                    ser.close()
                break   #Stop execution of the script
        else:
            # Case 2: format 'char:value;' (e.g., 'p:1.23;')
            if ':' in command:
                try:
                    constant_name, value_str = command.split(":", 1)
                    constant_value = float(value_str)

                    if DEVELOPING:
                        print(f"constant_name = {constant_name}, constant_value = {constant_value}")

                    # Handle based on the constant_name
                    if constant_name == 'a':
                        lineInterval = constant_value
                    elif constant_name == 'b':
                        stopDelay = constant_value
                    else:
                        if DEVELOPING: print("Unknown constant:", constant_name)

                except ValueError:
                    if DEVELOPING: print("Invalid format received:", command)

            else:
                # If it's not in the expected format, treat it as your lineInterval
                lineInterval = command
                if DEVELOPING:
                    print("Line Interval = ", lineInterval)


    if DEVELOPING == 1 or line_count!=-1: # do all the processes, either if we are developing the code, or we are running a lap. 
        if CAM_TYPE==1:
            success, frame = cap.read()
        elif CAM_TYPE==0: 
            frame = picam2.capture_array()
            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

        frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        cropped_frame = frame[100:400, 150:590]
        cropped_hsv   = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2HSV)
        blue_line_mask = cv2.inRange(cropped_hsv, blue_line_lower_bound, blue_line_upper_bound)
        blue_line_masked_frame = cv2.bitwise_and(cropped_frame, cropped_frame, mask = blue_line_mask)
        
        orange_line_mask = cv2.inRange(cropped_hsv, orange_line_lower_bound, orange_line_upper_bound)
        orange_line_masked_frame = cv2.bitwise_and(cropped_frame, cropped_frame, mask = orange_line_mask)
        combined_line_mask = cv2.bitwise_or(blue_line_masked_frame, orange_line_masked_frame)

        blue_line_contours, _ = cv2.findContours(blue_line_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        orange_line_contours, _ = cv2.findContours(orange_line_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if directionSentFlag == 0: #If we haven't send the round direction to the LLM yet
            #This basically measures, which color of threshold area do we get first
            #Checking for blue line
            for contour_index, contour in enumerate(blue_line_contours): 
                area = cv2.contourArea(contour)
                #print("blue = ", area)
                if cv2.contourArea(contour) > MIN_LINE_AREA:
                    if SERIAL_READY:
                        ser.write("b;".encode('utf-8'))
                    if DEVELOPING:
                        print("Serial: b;")
                    directionSentFlag = 1
                    break
            #Checking for orange line
            for cntour_index, contour in enumerate(orange_line_contours): 
                area = cv2.contourArea(contour)
                #print("orange = ", area)
                if area > MIN_LINE_AREA:
                    if SERIAL_READY:
                        ser.write("o;".encode('utf-8'))
                    if DEVELOPING: 
                        print("Serial: o;")
                    directionSentFlag = 1
                    break
                
        # --- Get Trackbar Positions for general HSV tuning ---
        if TUNE_HSV == 1 and DEVELOPING==1:
            g_l_h = cv2.getTrackbarPos("Green L - H", "HSV Trackbars") #g_l_h = green object's lower hue value
            g_l_s = cv2.getTrackbarPos("Green L - S", "HSV Trackbars")
            g_l_v = cv2.getTrackbarPos("Green L - V", "HSV Trackbars")
            g_u_h = cv2.getTrackbarPos("Green U - H", "HSV Trackbars")
            g_u_s = cv2.getTrackbarPos("Green U - S", "HSV Trackbars")
            g_u_v = cv2.getTrackbarPos("Green U - V", "HSV Trackbars")
                        # Define bounds for the general trackbar mask
            lower_bound_green = np.array([g_l_h, g_l_s, g_l_v])
            upper_bound_green = np.array([g_u_h, g_u_s, g_u_v])

            r_l_h1 = cv2.getTrackbarPos("Red L - H1", "HSV Trackbars") #r_l_h = red object's lower hue value
            r_l_h2 = cv2.getTrackbarPos("Red L - H2", "HSV Trackbars") #r_l_h = red object's lower hue value

            r_l_s = cv2.getTrackbarPos("Red L - S", "HSV Trackbars")
            r_l_v = cv2.getTrackbarPos("Red L - V", "HSV Trackbars")

            r_u_h1 = cv2.getTrackbarPos("Red U - H1", "HSV Trackbars")
            r_u_h2 = cv2.getTrackbarPos("Red U - H2", "HSV Trackbars")

            r_u_s = cv2.getTrackbarPos("Red U - S", "HSV Trackbars")
            r_u_v = cv2.getTrackbarPos("Red U - V", "HSV Trackbars")

            lower_bound1_red = np.array([r_l_h1, r_l_s, r_l_v])
            upper_bound1_red = np.array([r_u_h1, r_u_s, r_u_v])

            lower_bound2_red = np.array([r_l_h2, r_l_s, r_l_v])
            upper_bound2_red = np.array([r_u_h2, r_u_s, r_u_v])
        # cv2.createTrackbar("Blue Line L_V", "Line HSV trackbars",255, 255, nothing )

        # cv2.createTrackbar("Orange Line L_H", "Line HSV trackbars", 0, 179, nothing)
            bl_l_h = cv2.getTrackbarPos("Blue Line L_H", "Line HSV trackbars") #bl_l_h = blue line lower hue
            bl_l_s = cv2.getTrackbarPos("Blue Line L_S", "Line HSV trackbars")
            bl_l_v = cv2.getTrackbarPos("Blue Line L_V", "Line HSV trackbars")
        
            bl_u_h = cv2.getTrackbarPos("Blue Line U_H", "Line HSV trackbars") 
            bl_u_s = cv2.getTrackbarPos("Blue Line U_S", "Line HSV trackbars")
            bl_u_v = cv2.getTrackbarPos("Blue Line U_V", "Line HSV trackbars")
            blue_line_lower_bound = np.array([bl_l_h, bl_l_s , bl_l_v ])
            blue_line_upper_bound = np.array([bl_u_h, bl_u_s,  bl_u_v ])

            or_l_h = cv2.getTrackbarPos("Orange Line L_H", "Line HSV trackbars") #or_l_h = orange line lower hue
            or_l_s = cv2.getTrackbarPos("Orange Line L_S", "Line HSV trackbars")
            or_l_v = cv2.getTrackbarPos("Orange Line L_V", "Line HSV trackbars")

            or_u_h = cv2.getTrackbarPos("Orange Line U_H", "Line HSV trackbars") #or_l_h = orange line lower hue
            or_u_s = cv2.getTrackbarPos("Orange Line U_S", "Line HSV trackbars")
            or_u_v = cv2.getTrackbarPos("Orange Line U_V", "Line HSV trackbars")
        

        # Green object mask
        green_mask = cv2.inRange(hsv, lower_bound_green, upper_bound_green)
        green_masked_frame = cv2.bitwise_and(frame,frame,  mask = green_mask)
        #Why frame is passed two times in the above function?  Because cv2.bitwise_and() is designed to combine two images (pixel by pixel using the AND operation). If you want to apply a mask on a single image (frame), you simply bitwise AND it with itself. That way: Each pixel P in the result becomes: P = frame AND frame → which is just P, but only where the mask is non-zero.
        contours_green, _ = cv2.findContours(
            green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE   
        )
        obstaclePresent = 0
        obstacleArea = 0
        for contour_id, contour in enumerate(contours_green):
            area = cv2.contourArea(contour)
            x,y,w,h = cv2.boundingRect(contour) #Assuming that the camera's lense surface is parallel to one of the side of the wro obstacle
            if area > MIN_OBJECT_AREA and  w!=0: #If the distance reading has been reported once, we won't send it over and over again 
                obstaclePresent = 1
                obstacleArea = math.floor(area)
                break

        if obstaclePresent :
                if serialFlag2==1:
                    #distance = math.floor(estimate_distance(w))
                    if SERIAL_READY==1: 
                        ser.write(f"G:{area};".encode('utf-8'))
                    if DEVELOPING:
                        print(f"Serial: G:{area};")
                    serialFlag2 = 0  #The object is present in front of the vehicle, now we can send a 0 distance while it goes beyond the vision range. 
                    #serialFlag2=1  # Marking that we have sent the distance once, and won't sent this over and over again
        elif serialFlag2 ==0: # Camera is not encountering any blue object and we haven't reported it to the LLM 
                        if SERIAL_READY==1: 
                            ser.write("G:0;".encode('utf-8')) #Tells the LLM(low level microcontroller) that we are not seeing any blue object right now
                        if DEVELOPING:    
                            print("Serial: G:0; ")
                        serialFlag2 = 1


        # 1. Detect Red objects
        red_mask1 = cv2.inRange(hsv, lower_bound1_red, upper_bound1_red)
        red_mask2 = cv2.inRange(hsv, lower_bound2_red, upper_bound2_red)
        red_mask_combined = cv2.bitwise_or(red_mask1, red_mask2)
        red_masked_frame = cv2.bitwise_and(frame, frame, mask = red_mask_combined)
        
        #blue_image = cv2.bitwise_and(frame, frame, mask = blue_mask) # In blue_image we only see the pixels that are white in blue_mask, so we only see the particular color of the hsv range, all other pixels are made black. 
        contours_red, _ = cv2.findContours(
            red_mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE   
        )

        obstaclePresent = 0
        obstacleArea = 0
        for contour_id, contour in enumerate(contours_red):
            area = cv2.contourArea(contour)
            x,y,w,h = cv2.boundingRect(contour) #Assuming that the camera's lense surface is parallel to one of the side of the wro obstacle
            if area > MIN_OBJECT_AREA and  w!=0: #If the distance reading has been reported once, we won't send it over and over again 
                obstaclePresent = 1
                obstacleArea = math.floor(area)
                break

        if obstaclePresent :
                if serialFlag==1:
                    #distance = math.floor(estimate_distance(w))
                    if SERIAL_READY==1: 
                        ser.write(f"R:{area};".encode('utf-8'))
                    if DEVELOPING:
                        print(f"Serial: R:{area};")
                    serialFlag = 0  #The object is present in front of the vehicle, now we can send a 0 distance while it goes beyond the vision range. 
                    #serialFlag2=1  # Marking that we have sent the distance once, and won't sent this over and over again
        elif serialFlag ==0: # Camera is not encountering any blue object and we haven't reported it to the LLM 
                        if SERIAL_READY==1: 
                            ser.write("R:0;".encode('utf-8')) #Tells the LLM(low level microcontroller) that we are not seeing any blue object right now
                        if DEVELOPING:
                            print("Serial: R:0; ")
                        serialFlag = 1 #We won't send this "No blue object in vision range" continuosly, we'll just send it once

    
        stackedImages = stackImages(0.6, ([frame, green_masked_frame, red_masked_frame],
                                                [blue_line_masked_frame, orange_line_masked_frame, combined_line_mask]))
    
        if DEVELOPING:
            cv2.imshow("Frames", stackedImages)
            key = cv2.waitKey(1)  #Purpose of the above expression: It waits for a speciefied amount of time(in milliseconds) for a key event to occur. This small delay is crucial when processing video streams, as it allows the system to display each frame for a brief period, creating the illusion of continuosu motion. Without this delay, the frames would be processed and displayed so quickly that the video would appear as a blur or not be visible at all. And in most cases, the window will have "Not responding" problem and ultimately crash. During this delay, cv2.waitKey(1) also checks if any key has been pressed. If any key has been prssed. If a key is pressed within the 1-millisecond window, it returns the ascii value fo that pressed key. If no key is pressed within that time, it returns -1. 
            if key == ord('q'): # Stops the execution of the entire python program
                if SERIAL_READY==1:
                    ser.close()
                break
            elif key == ord('s'):  #Stops/Starts the car
                if SERIAL_READY:
                    ser.write("x;".encode('utf-8')) 

                print("Serial: x;")
            elif key == ord('r'):
                directionSentFlag = 0
            
        



